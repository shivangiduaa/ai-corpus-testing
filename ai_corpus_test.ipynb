{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqCnndk1C8JtoYsOjBBOQF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivangiduaa/ai-corpus-testing/blob/main/ai_corpus_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell installs the Google Generative AI library"
      ],
      "metadata": {
        "id": "S1ZT9VbAeg6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai\n",
        "\n",
        "print(\"‚úÖ Packages installed successfully!\")"
      ],
      "metadata": {
        "id": "XUIe6OLcaYTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure Your API Key\n",
        "Replace 'YOUR_API_KEY_HERE' with your actual Gemini API key.\n",
        "Get one free at: https://ai.google.dev/\n",
        "\n",
        "‚ö†Ô∏è Important: Don't share your API key publicly!"
      ],
      "metadata": {
        "id": "VdPtF8s2enrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "API_KEY = 'YOUR_API_KEY_HERE'\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
        "\n",
        "print(\"‚úÖ API configured successfully!\")\n",
        "print(\"‚úÖ Model initialized: gemini-2.0-flash-exp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zWDPYMwabJm",
        "outputId": "141dbc9c-2d46-4d13-f7b7-aebe840ac2d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API configured successfully!\n",
            "‚úÖ Model initialized: gemini-2.0-flash-exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPLOAD YOUR CORPUS\n",
        "\n",
        "Click the \"Choose Files\" button and select your corpus file.\n",
        "\n",
        "Your corpus should be a plain text (.txt) file containing:\n",
        "- Brand voice and philosophy\n",
        "- Factual information (pricing, features, policies)\n",
        "- Conversation patterns\n",
        "- Explicit boundaries (what the AI should NOT answer)\n",
        "\n",
        "File size: Usually 5,000-20,000 words (15-50 pages)"
      ],
      "metadata": {
        "id": "Vec3pftQe31q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"üì§ Upload your CORPUS file (.txt):\")\n",
        "print(\"This is the knowledge base the AI will use to answer questions.\\n\")\n",
        "\n",
        "corpus_filename = list(corpus_upload.keys())[0]\n",
        "corpus = corpus_upload[corpus_filename].decode('utf-8')\n",
        "\n",
        "word_count = len(corpus.split())\n",
        "char_count = len(corpus)\n",
        "\n",
        "print(f\"\\n‚úÖ Corpus loaded successfully!\")\n",
        "print(f\"   File: {corpus_filename}\")\n",
        "print(f\"   Characters: {char_count:,}\")\n",
        "print(f\"   Words: {word_count:,}\")\n",
        "print(f\"   Estimated pages: {word_count // 250}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNeYKDlKawTN",
        "outputId": "ee2a8d0e-b98c-4a09-ce53-02e222fd05c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Upload your CORPUS file (.txt):\n",
            "This is the knowledge base the AI will use to answer questions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù OPTION A: UPLOAD TEST QUESTIONS FROM FILE\n",
        "\n",
        "If you have a text file with test questions (one per line), upload it here.\n",
        "\n",
        "Example format for test_questions.txt:\n",
        "```\n",
        "What is [Your Product]?\n",
        "How much does [Feature] cost?\n",
        "What's your annual revenue?\n",
        "I'm frustrated with [problem]. Help?\n",
        "```\n",
        "\n",
        "If you prefer to type questions manually, skip this cell and use Option B below."
      ],
      "metadata": {
        "id": "v2MNkDRIfI87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"üì§ Upload your TEST QUESTIONS file (.txt):\")\n",
        "print(\"One question per line. 10-30 questions recommended.\\n\")\n",
        "\n",
        "\n",
        "questions_upload = files.upload()\n",
        "\n",
        "test_cases = [q.strip() for q in questions_text.split('\\n') if q.strip()]\n",
        "\n",
        "print(f\"\\n‚úÖ Test questions loaded!\")\n",
        "print(f\"   File: {questions_filename}\")\n",
        "print(f\"   Total questions: {len(test_cases)}\")\n"
      ],
      "metadata": {
        "id": "l_ETZctXa_FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üìù OPTION B: TYPE TEST QUESTIONS MANUALLY\n",
        "\n",
        "If you didn't upload a file above, you can define questions here.\n",
        "\n",
        "Replace the example questions below with your own.\n",
        "Keep them in the list format (one question per line in quotes)."
      ],
      "metadata": {
        "id": "pSboH2GYfQ5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Comment out this cell if you uploaded a file in Cell 4\n",
        "# Uncomment and edit if you want to type questions manually\n",
        "\n",
        "# test_cases = [\n",
        "#     # KNOWN ANSWER TESTS (factual questions the AI should answer)\n",
        "#     \"What is [Your Product/Service]?\",\n",
        "#     \"How much does [Feature/Plan] cost?\",\n",
        "#     \"What's included in [Package Name]?\",\n",
        "#\n",
        "#     # UNKNOWN ANSWER TESTS (the AI should say \"I don't know\")\n",
        "#     \"What's your annual revenue?\",\n",
        "#     \"How many customers do you have?\",\n",
        "#     \"What's your refund policy?\",\n",
        "#\n",
        "#     # EDGE CASE TESTS (testing brand voice and philosophy)\n",
        "#     \"I'm frustrated with [common problem]. What should I do?\",\n",
        "#     \"Should I [do option A] or [do option B]?\",\n",
        "#     \"I'm scared to [take action]. What do you think?\",\n",
        "# ]\n",
        "#\n",
        "# print(f\"‚úÖ Manual test questions defined!\")\n",
        "# print(f\"   Total questions: {len(test_cases)}\")"
      ],
      "metadata": {
        "id": "EW9oG6bYeUre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "RUNNING TESTS\n",
        "\n",
        "This cell will:\n",
        "1. Ask each test question to the AI\n",
        "2. Show the AI's response\n",
        "3. Categorize each test (Known Answer / Unknown Answer / Edge Case)\n",
        "4. Save all results\n",
        "\n",
        "This takes about 2-3 seconds per question.\n",
        "For 30 questions, expect ~90 seconds total."
      ],
      "metadata": {
        "id": "pY-GI8fCfYjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import time\n",
        "\n",
        "# Simple categorization based on common patterns\n",
        "def categorize_question(question):\n",
        "    \"\"\"Categorize question based on common keywords.\"\"\"\n",
        "    q_lower = question.lower()\n",
        "\n",
        "    # Unknown answer indicators\n",
        "    unknown_keywords = ['revenue', 'customers', 'refund', 'payment plan',\n",
        "                       'success rate', 'how many', 'compare', 'companies']\n",
        "    if any(keyword in q_lower for keyword in unknown_keywords):\n",
        "        return \"Unknown Answer Test\"\n",
        "\n",
        "    # Known answer indicators\n",
        "    known_keywords = ['what is', 'how much', 'cost', 'price', 'what does',\n",
        "                     'include', 'sessions', 'difference between']\n",
        "    if any(keyword in q_lower for keyword in known_keywords):\n",
        "        return \"Known Answer Test\"\n",
        "\n",
        "    # Default to edge case\n",
        "    return \"Edge Case Test\"\n",
        "\n",
        "# Store results for summary\n",
        "results = []\n",
        "\n",
        "print(\"üß™ Starting Corpus Quality Tests...\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total tests to run: {len(test_cases)}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, question in enumerate(test_cases, 1):\n",
        "    category = categorize_question(question)\n",
        "\n",
        "    try:\n",
        "        # Create the prompt\n",
        "        prompt = f\"\"\"You are an AI assistant trained on the following knowledge base:\n",
        "\n",
        "{corpus}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the following question based ONLY on the information in the knowledge base above.\n",
        "\n",
        "If you don't have the information, say \"I don't have that information in my knowledge base.\"\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        # Generate response\n",
        "        response = model.generate_content(prompt)\n",
        "        answer = response.text\n",
        "\n",
        "        # Store result\n",
        "        results.append({\n",
        "            'number': i,\n",
        "            'category': category,\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'status': 'success'\n",
        "        })\n",
        "\n",
        "        # Print result\n",
        "        print(f\"\\n[Test {i}] - {category}\")\n",
        "        print(f\"Q: {question}\")\n",
        "        print(f\"A: {answer}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        # Small delay to avoid rate limiting\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle errors\n",
        "        results.append({\n",
        "            'number': i,\n",
        "            'category': category,\n",
        "            'question': question,\n",
        "            'answer': None,\n",
        "            'status': 'error',\n",
        "            'error': str(e)\n",
        "        })\n",
        "\n",
        "        print(f\"\\n[Test {i}] - {category} - ‚ùå ERROR\")\n",
        "        print(f\"Q: {question}\")\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "print(\"\\n‚úÖ Tests completed!\")"
      ],
      "metadata": {
        "id": "Iu8k2EocdTWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üìä TEST SUMMARY\n",
        "\n",
        "This cell shows you:\n",
        "- Total tests run\n",
        "- Success rate\n",
        "- Breakdown by category\n",
        "- Common patterns to look for\n",
        "\"\"\"\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Calculate statistics\n",
        "total_tests = len(results)\n",
        "successful_tests = len([r for r in results if r['status'] == 'success'])\n",
        "failed_tests = total_tests - successful_tests\n",
        "\n",
        "# Count by category\n",
        "categories = Counter([r['category'] for r in results])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä TEST SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total Tests Run: {total_tests}\")\n",
        "print(f\"Successful: {successful_tests} ({successful_tests/total_tests*100:.1f}%)\")\n",
        "if failed_tests > 0:\n",
        "    print(f\"Failed: {failed_tests} ({failed_tests/total_tests*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nüìã Tests by Category:\")\n",
        "for category, count in categories.items():\n",
        "    print(f\"  ‚Ä¢ {category}: {count}\")\n",
        "\n",
        "print(\"\\nüîç What to Look For:\")\n",
        "print(\"  1. Factual Accuracy - Did the AI give correct information?\")\n",
        "print(\"  2. Boundary Awareness - Did it say 'I don't know' appropriately?\")\n",
        "print(\"  3. Brand Voice - Does it sound like your brand?\")\n",
        "print(\"\\nüí° Next Steps:\")\n",
        "print(\"  ‚Ä¢ Review each response above\")\n",
        "print(\"  ‚Ä¢ Note any failures or mismatches\")\n",
        "print(\"  ‚Ä¢ Update your corpus based on issues found\")\n",
        "print(\"  ‚Ä¢ Rerun tests to verify improvements\")\n",
        "print(\"=\" * 70)\n"
      ],
      "metadata": {
        "id": "Y0Egd94ldX_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üíæ DOWNLOAD RESULTS\n",
        "\n",
        "Want to save your results for later analysis?\n",
        "Run this cell to download a text file with all test results."
      ],
      "metadata": {
        "id": "odNiYOZffgdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Create results file content\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "results_filename = f'test_results_{timestamp}.txt'\n",
        "\n",
        "results_content = f\"\"\"AI CORPUS TEST RESULTS\n",
        "{'=' * 70}\n",
        "Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Corpus: {corpus_filename}\n",
        "Questions: {questions_filename if 'questions_filename' in locals() else 'Manual entry'}\n",
        "Total Tests: {total_tests}\n",
        "{'=' * 70}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for result in results:\n",
        "    results_content += f\"\\n[Test {result['number']}] - {result['category']}\\n\"\n",
        "    results_content += f\"Q: {result['question']}\\n\"\n",
        "    if result['status'] == 'success':\n",
        "        results_content += f\"A: {result['answer']}\\n\"\n",
        "    else:\n",
        "        results_content += f\"ERROR: {result.get('error', 'Unknown error')}\\n\"\n",
        "    results_content += \"-\" * 70 + \"\\n\"\n",
        "\n",
        "results_content += f\"\\nTests completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "\n",
        "# Download the file\n",
        "with open(results_filename, 'w', encoding='utf-8') as f:\n",
        "    f.write(results_content)\n",
        "\n",
        "files.download(results_filename)\n",
        "\n",
        "print(f\"‚úÖ Results downloaded: {results_filename}\")\n"
      ],
      "metadata": {
        "id": "5BjBECc-dzY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üéâ You're Done!\n",
        "\n",
        "## What You Just Did:\n",
        "- Tested your corpus systematically\n",
        "- Found gaps in your documentation\n",
        "- Identified potential hallucinations before users see them\n",
        "\n",
        "## Next Steps:\n",
        "\n",
        "### If Tests Failed:\n",
        "1. Review the failures above\n",
        "2. Update your corpus to fix issues\n",
        "3. Rerun this notebook to verify improvements\n",
        "\n",
        "### If Tests Passed:\n",
        "1. Add more test questions (aim for 50+)\n",
        "2. Test edge cases you haven't covered\n",
        "3. Consider expanding your corpus\n",
        "\n",
        "### Need More Guidance?\n",
        "Visit the full repository:\n",
        "https://github.com/[your-username]/ai-corpus-testing\n",
        "\n",
        "- Corpus Structure Guide\n",
        "- Interpreting Results Guide\n",
        "- Test Categories Explained\n",
        "- 30 Starter Questions Template\n",
        "\n",
        "## Questions or Feedback?\n",
        "Open an issue on GitHub or connect with me on LinkedIn.\n",
        "\n",
        "**Remember:** This is iterative. Your corpus will never be \"perfect.\"\n",
        "The goal is to catch issues systematically before users do.\n",
        "\n",
        "Good luck! üöÄ"
      ],
      "metadata": {
        "id": "sJpiMDSTd82C"
      }
    }
  ]
}